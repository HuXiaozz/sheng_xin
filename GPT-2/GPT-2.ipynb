{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c9bd1a8-e395-4883-be5c-7504cbc9fbe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at ./GPT-2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 425/425 [00:00<00:00, 2240.28 examples/s]\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/training_args.py:1494: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='240' max='240' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [240/240 02:17, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.677200</td>\n",
       "      <td>0.694218</td>\n",
       "      <td>0.508235</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PredictionOutput(predictions=array([[ 2.26898193e-02, -3.03649902e-02],\n",
      "       [-5.37597656e-01, -6.26464844e-01],\n",
      "       [-1.58996582e-02,  3.30200195e-02],\n",
      "       [ 8.11157227e-02,  4.89501953e-02],\n",
      "       [-3.43017578e-02, -1.34521484e-01],\n",
      "       [-2.37792969e-01, -2.64160156e-01],\n",
      "       [-3.97949219e-01, -5.11718750e-01],\n",
      "       [-5.83496094e-01, -6.38671875e-01],\n",
      "       [-6.87011719e-01, -6.26464844e-01],\n",
      "       [-1.42578125e-01, -1.52099609e-01],\n",
      "       [-5.60058594e-01, -6.54296875e-01],\n",
      "       [-5.62500000e-01, -6.23535156e-01],\n",
      "       [-4.09423828e-01, -4.83398438e-01],\n",
      "       [-3.97644043e-02, -9.10644531e-02],\n",
      "       [-3.78417969e-01, -4.52636719e-01],\n",
      "       [-2.55126953e-01, -2.95166016e-01],\n",
      "       [-4.04541016e-01, -4.48242188e-01],\n",
      "       [-4.05029297e-01, -4.48486328e-01],\n",
      "       [-3.61022949e-02, -9.23461914e-02],\n",
      "       [-1.32324219e-01, -1.29028320e-01],\n",
      "       [-4.55810547e-01, -5.55664062e-01],\n",
      "       [-5.40039062e-01, -6.63574219e-01],\n",
      "       [ 1.30176544e-03, -1.20910645e-01],\n",
      "       [-1.76879883e-01, -1.46484375e-01],\n",
      "       [ 3.05023193e-02, -5.38330078e-02],\n",
      "       [-3.85742188e-01, -4.75341797e-01],\n",
      "       [-5.70800781e-01, -6.67968750e-01],\n",
      "       [-5.72265625e-01, -6.78222656e-01],\n",
      "       [-4.83398438e-01, -6.08886719e-01],\n",
      "       [-5.44433594e-01, -6.57714844e-01],\n",
      "       [-4.03076172e-01, -4.47021484e-01],\n",
      "       [ 7.82012939e-03, -1.13769531e-01],\n",
      "       [-9.87548828e-02, -1.22436523e-01],\n",
      "       [ 1.81274414e-02, -7.83081055e-02],\n",
      "       [-4.16503906e-01, -5.10253906e-01],\n",
      "       [-3.62304688e-01, -4.31152344e-01],\n",
      "       [-5.87890625e-01, -6.32324219e-01],\n",
      "       [-5.58105469e-01, -6.44531250e-01],\n",
      "       [-4.61914062e-01, -5.93261719e-01],\n",
      "       [-9.39941406e-02, -2.53173828e-01],\n",
      "       [-2.77832031e-01, -3.54980469e-01],\n",
      "       [-6.13098145e-02, -1.33178711e-01],\n",
      "       [-4.57763672e-01, -6.02539062e-01],\n",
      "       [ 8.31604004e-03, -5.52673340e-02],\n",
      "       [-1.06445312e-01, -1.85180664e-01],\n",
      "       [-3.76892090e-02, -9.13085938e-02],\n",
      "       [-2.64160156e-01, -3.42285156e-01],\n",
      "       [ 6.54296875e-02, -2.41851807e-02],\n",
      "       [-3.75366211e-02, -1.14990234e-01],\n",
      "       [-4.04785156e-01, -4.89990234e-01],\n",
      "       [-4.85351562e-01, -6.08886719e-01],\n",
      "       [-1.35009766e-01, -1.77124023e-01],\n",
      "       [-4.61425781e-01, -5.55175781e-01],\n",
      "       [-4.12841797e-01, -4.89257812e-01],\n",
      "       [-6.43554688e-01, -6.53808594e-01],\n",
      "       [-6.39648438e-02, -8.16040039e-02],\n",
      "       [-6.50878906e-01, -6.45507812e-01],\n",
      "       [-5.92285156e-01, -6.53320312e-01],\n",
      "       [ 4.02221680e-02, -3.02734375e-02],\n",
      "       [-6.12304688e-01, -7.08984375e-01],\n",
      "       [-6.23474121e-02, -7.09838867e-02],\n",
      "       [-4.02099609e-01, -4.84375000e-01],\n",
      "       [-9.29565430e-02, -6.93359375e-02],\n",
      "       [-5.47363281e-01, -6.14746094e-01],\n",
      "       [-2.36816406e-02, -6.58569336e-02],\n",
      "       [ 1.30844116e-02,  1.04370117e-02],\n",
      "       [-4.79248047e-01, -6.03515625e-01],\n",
      "       [ 7.46250153e-04, -2.78472900e-02],\n",
      "       [-5.83496094e-01, -6.66992188e-01],\n",
      "       [-1.22924805e-01, -1.00646973e-01],\n",
      "       [-1.14440918e-01, -2.52838135e-02],\n",
      "       [ 7.12890625e-02, -3.80249023e-02],\n",
      "       [-5.62988281e-01, -6.35742188e-01],\n",
      "       [-2.84912109e-01, -3.12744141e-01],\n",
      "       [-5.01464844e-01, -6.24511719e-01],\n",
      "       [-5.05371094e-01, -6.13281250e-01],\n",
      "       [-4.54101562e-01, -5.52734375e-01],\n",
      "       [-5.56030273e-02, -1.00585938e-01],\n",
      "       [ 3.76892090e-02,  3.59497070e-02],\n",
      "       [-5.15136719e-02, -1.04858398e-01],\n",
      "       [-2.04010010e-02, -5.22766113e-02],\n",
      "       [-5.04394531e-01, -6.42089844e-01],\n",
      "       [-1.96228027e-02, -1.05590820e-01],\n",
      "       [-3.79394531e-01, -4.65820312e-01],\n",
      "       [-5.69335938e-01, -6.07421875e-01],\n",
      "       [-3.62014771e-03, -1.26464844e-01],\n",
      "       [-5.07812500e-01, -6.53320312e-01],\n",
      "       [-1.01623535e-01, -9.39941406e-02],\n",
      "       [-9.83276367e-02, -1.26464844e-01],\n",
      "       [-3.42773438e-01, -4.02832031e-01],\n",
      "       [-3.86718750e-01, -4.56542969e-01],\n",
      "       [-1.00463867e-01, -1.08276367e-01],\n",
      "       [-4.57275391e-01, -6.10839844e-01],\n",
      "       [ 1.36108398e-02, -1.10900879e-01],\n",
      "       [-4.91455078e-01, -5.89843750e-01],\n",
      "       [-5.01464844e-01, -6.62109375e-01],\n",
      "       [-4.57763672e-01, -5.96679688e-01],\n",
      "       [-4.87548828e-01, -5.77148438e-01],\n",
      "       [-1.44287109e-01, -1.41723633e-01],\n",
      "       [-5.98632812e-01, -6.31347656e-01],\n",
      "       [-1.33911133e-01, -1.01867676e-01],\n",
      "       [-3.93371582e-02, -6.95190430e-02],\n",
      "       [-5.37597656e-01, -6.31835938e-01],\n",
      "       [-8.28552246e-03, -2.95257568e-02],\n",
      "       [-4.17724609e-01, -5.17089844e-01],\n",
      "       [ 5.18493652e-02, -4.02526855e-02],\n",
      "       [-1.93634033e-02, -8.74023438e-02],\n",
      "       [-6.21582031e-01, -6.91894531e-01],\n",
      "       [-4.63134766e-01, -5.72265625e-01],\n",
      "       [-4.17724609e-01, -5.29296875e-01],\n",
      "       [-3.05419922e-01, -3.56689453e-01],\n",
      "       [-6.30859375e-01, -7.00195312e-01],\n",
      "       [-4.97558594e-01, -6.40136719e-01],\n",
      "       [ 2.83050537e-02, -4.17480469e-02],\n",
      "       [ 4.28771973e-03, -5.86242676e-02],\n",
      "       [-2.12402344e-01, -2.63671875e-01],\n",
      "       [ 2.34832764e-02, -8.22143555e-02],\n",
      "       [-2.30468750e-01, -2.54638672e-01],\n",
      "       [ 1.77764893e-02,  4.71878052e-03],\n",
      "       [-5.76660156e-01, -6.73828125e-01],\n",
      "       [-8.52050781e-02, -1.03027344e-01],\n",
      "       [-8.89892578e-02, -7.79418945e-02],\n",
      "       [-1.03881836e-01, -9.89990234e-02],\n",
      "       [-5.18066406e-01, -5.92285156e-01],\n",
      "       [-3.92089844e-01, -4.57275391e-01],\n",
      "       [-1.52709961e-01, -2.55615234e-01],\n",
      "       [-3.09082031e-01, -3.33007812e-01],\n",
      "       [-2.94433594e-01, -3.75488281e-01],\n",
      "       [-4.88769531e-01, -6.16699219e-01],\n",
      "       [-3.97644043e-02, -1.10656738e-01],\n",
      "       [-1.60766602e-01, -9.72900391e-02],\n",
      "       [-3.08105469e-01, -3.82324219e-01],\n",
      "       [-3.79882812e-01, -4.77050781e-01],\n",
      "       [-5.31738281e-01, -6.40136719e-01],\n",
      "       [-4.88037109e-01, -6.34765625e-01],\n",
      "       [-7.15942383e-02, -9.86328125e-02],\n",
      "       [-1.79199219e-01, -1.32812500e-01],\n",
      "       [ 1.11222267e-04,  3.14636230e-02],\n",
      "       [-5.69335938e-01, -6.74316406e-01],\n",
      "       [-5.71777344e-01, -6.66503906e-01],\n",
      "       [-4.88037109e-01, -6.16699219e-01],\n",
      "       [-1.02233887e-01, -7.30590820e-02],\n",
      "       [-5.24902344e-01, -6.25000000e-01],\n",
      "       [-3.55224609e-02, -4.11987305e-02],\n",
      "       [-5.56945801e-02, -1.13098145e-01],\n",
      "       [-1.66503906e-01, -2.05566406e-01],\n",
      "       [-3.61816406e-01, -4.21386719e-01],\n",
      "       [-6.54296875e-01, -6.23535156e-01],\n",
      "       [-2.71728516e-01, -3.27148438e-01],\n",
      "       [ 1.35574341e-02, -8.69750977e-02],\n",
      "       [-4.57519531e-01, -5.76660156e-01],\n",
      "       [-1.86004639e-02, -5.00793457e-02],\n",
      "       [ 4.91027832e-02, -1.33514404e-02],\n",
      "       [-6.09863281e-01, -6.83593750e-01],\n",
      "       [-4.15283203e-01, -4.79248047e-01],\n",
      "       [ 3.37524414e-02, -9.88769531e-02],\n",
      "       [-5.04882812e-01, -6.55273438e-01],\n",
      "       [-8.74023438e-02, -4.99877930e-02],\n",
      "       [-3.78906250e-01, -4.48486328e-01],\n",
      "       [ 7.59124756e-03, -5.04760742e-02],\n",
      "       [-6.08886719e-01, -6.90429688e-01],\n",
      "       [ 1.08108521e-02, -6.09970093e-03],\n",
      "       [-3.96972656e-01, -4.49951172e-01],\n",
      "       [-7.73315430e-02, -1.28906250e-01],\n",
      "       [ 4.96387482e-04,  5.72967529e-03],\n",
      "       [-5.58105469e-01, -6.69921875e-01],\n",
      "       [ 6.32324219e-02,  5.42602539e-02],\n",
      "       [-4.29687500e-01, -5.17578125e-01],\n",
      "       [-1.70532227e-01, -1.63696289e-01],\n",
      "       [-4.35058594e-01, -5.52246094e-01],\n",
      "       [-3.63037109e-01, -4.10400391e-01],\n",
      "       [-5.36132812e-01, -6.70898438e-01],\n",
      "       [-7.43103027e-03, -8.92333984e-02],\n",
      "       [-7.37304688e-02,  1.77154541e-02],\n",
      "       [-1.34765625e-01, -1.45019531e-01],\n",
      "       [-1.78222656e-01, -2.26684570e-01],\n",
      "       [-4.64477539e-02, -1.29638672e-01],\n",
      "       [-4.81201172e-01, -5.98144531e-01],\n",
      "       [-3.83544922e-01, -4.68505859e-01],\n",
      "       [-5.63964844e-01, -6.28906250e-01],\n",
      "       [-5.14648438e-01, -6.57226562e-01],\n",
      "       [ 2.48107910e-02,  6.94274902e-03],\n",
      "       [-5.00976562e-01, -6.28906250e-01],\n",
      "       [-5.00000000e-01, -6.44531250e-01],\n",
      "       [-5.09277344e-01, -6.42089844e-01],\n",
      "       [-4.23828125e-01, -4.81689453e-01],\n",
      "       [-8.50830078e-02, -6.84204102e-02],\n",
      "       [-1.18103027e-01, -9.82666016e-02],\n",
      "       [-4.23095703e-01, -5.26855469e-01],\n",
      "       [ 7.78198242e-02,  3.12805176e-02],\n",
      "       [ 6.74438477e-02,  4.29382324e-02],\n",
      "       [-3.51318359e-01, -4.20166016e-01],\n",
      "       [ 1.18103027e-02, -5.11779785e-02],\n",
      "       [-4.08447266e-01, -5.19531250e-01],\n",
      "       [-3.74145508e-02, -7.23266602e-02],\n",
      "       [-2.89306641e-02, -4.29077148e-02],\n",
      "       [-9.75952148e-02, -1.66870117e-01],\n",
      "       [ 3.10058594e-02, -1.24450684e-01],\n",
      "       [ 2.38952637e-02, -3.49731445e-02],\n",
      "       [-2.83203125e-01, -3.44482422e-01],\n",
      "       [-3.56750488e-02, -1.07116699e-01],\n",
      "       [-3.46679688e-01, -4.20166016e-01],\n",
      "       [-5.75195312e-01, -4.48974609e-01],\n",
      "       [ 3.55148315e-03, -2.87170410e-02],\n",
      "       [-5.12695312e-01, -6.23046875e-01],\n",
      "       [-2.57080078e-01, -3.16406250e-01],\n",
      "       [-6.45141602e-02, -1.18408203e-01],\n",
      "       [-1.01440430e-01, -1.71142578e-01],\n",
      "       [-6.24511719e-01, -5.04394531e-01],\n",
      "       [-6.82373047e-02, -7.44018555e-02],\n",
      "       [-3.56864929e-03, -5.95092773e-02],\n",
      "       [-5.48828125e-01, -6.47460938e-01],\n",
      "       [-6.35742188e-01, -7.17773438e-01],\n",
      "       [ 2.10571289e-02, -7.83081055e-02],\n",
      "       [ 7.83691406e-02,  2.27966309e-02],\n",
      "       [ 4.50744629e-02,  3.99475098e-02],\n",
      "       [-4.98291016e-01, -6.19140625e-01],\n",
      "       [ 3.95584106e-03, -1.63269043e-02],\n",
      "       [-5.38085938e-01, -5.95703125e-01],\n",
      "       [-5.82519531e-01, -6.23046875e-01],\n",
      "       [-1.15539551e-01, -1.03149414e-01],\n",
      "       [-2.92816162e-02, -9.53979492e-02]], dtype=float32), label_ids=array([0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1,\n",
      "       1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1,\n",
      "       1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1,\n",
      "       0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0,\n",
      "       0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1,\n",
      "       0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0,\n",
      "       1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0,\n",
      "       1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0,\n",
      "       1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0,\n",
      "       0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1,\n",
      "       1, 1]), metrics={'test_loss': 0.6952927708625793, 'test_accuracy': 0.46846846846846846, 'test_runtime': 1.1647, 'test_samples_per_second': 190.601, 'test_steps_per_second': 12.02})\n"
     ]
    }
   ],
   "source": [
    "#gpt2\n",
    "import torch.nn as nn\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, DataCollatorWithPadding, TrainingArguments, Trainer\n",
    "import torch\n",
    "from transformers import GPT2Config, GPT2Tokenizer, GPT2ForSequenceClassification\n",
    "import numpy as np\n",
    "import evaluate\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "\n",
    "# ËÆæÁΩÆÈöèÊú∫ÁßçÂ≠ê\n",
    "torch.manual_seed(48)\n",
    "np.random.seed(56)\n",
    "\n",
    "# Âä†ËΩΩÈ¢ÑËÆ≠ÁªÉÁöÑGPT-2Ê®°ÂûãÂíåtokenizer\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"./GPT-2\")\n",
    "\n",
    "config = GPT2Config.from_pretrained(\"./GPT-2\")\n",
    "\n",
    "\n",
    "\n",
    "# Ë∞ÉÊï¥Ê®°ÂûãÁöÑÂ±ÇÊï∞\n",
    "config.n_layer = 2  # ËÆæÁΩÆ‰∏∫6Â±Ç\n",
    "\n",
    "model = GPT2ForSequenceClassification.from_pretrained(\"./GPT-2\",config = config)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Âä†ËΩΩËÆ°ÁÆóÂ∑•ÂÖ∑\n",
    "metric = evaluate.load(\"./tools/accuracy.py\")\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Êï∞ÊçÆÊñá‰ª∂Ë∑ØÂæÑÔºåÊï∞ÊçÆÈúÄË¶ÅÊèêÂâç‰∏ãËΩΩ\n",
    "data_file = \"./data/train.csv\" \n",
    "\n",
    "\n",
    "# Âä†ËΩΩÊï∞ÊçÆÈõÜ\n",
    "dataset = load_dataset(\"csv\", data_files=data_file)\n",
    "dataset = dataset.filter(lambda x: x[\"seq\"] is not None)\n",
    "datasets = dataset[\"train\"].train_test_split(0.1)\n",
    "\n",
    "# Êï∞ÊçÆÈõÜÂ§ÑÁêÜ\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"GPT-2\")\n",
    "\n",
    "def process_function(examples):\n",
    "    for i in range(len(examples['seq'])):\n",
    "        examples['seq'][i] = ' '.join(list(examples['seq'][i]))\n",
    "    tokenized_examples = tokenizer(examples[\"seq\"], max_length=500, truncation=True)\n",
    "    tokenized_examples[\"labels\"] = examples[\"label\"]\n",
    "    return tokenized_examples\n",
    "\n",
    "tokenized_datasets = datasets.map(process_function, batched=True)\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "model.config.pad_token_id = model.config.eos_token_id\n",
    "tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
    "\n",
    "\n",
    "args = TrainingArguments(\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=1,\n",
    "    weight_decay=0.01,\n",
    "    save_steps = 4,\n",
    "    seed=4112,\n",
    "    output_dir=\"model_for_seqclassification\",\n",
    "    logging_steps=10,\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    save_strategy = \"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    fp16=True\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "  model,\n",
    "  args,\n",
    "  train_dataset=tokenized_datasets[\"train\"],\n",
    "  eval_dataset=tokenized_datasets[\"test\"],\n",
    "  tokenizer=tokenizer,\n",
    "  compute_metrics=compute_metrics,\n",
    " data_collator=DataCollatorWithPadding(tokenizer=tokenizer)\n",
    ")\n",
    "trainer.train()\n",
    "\n",
    "\n",
    "# Êï∞ÊçÆÊñá‰ª∂Ë∑ØÂæÑÔºåÊï∞ÊçÆÈúÄË¶ÅÊèêÂâç‰∏ãËΩΩ\n",
    "data_file = \"./data/test.csv\" \n",
    "\n",
    "# Âä†ËΩΩÊï∞ÊçÆÈõÜ\n",
    "dataset = load_dataset(\"csv\", data_files=data_file)\n",
    "dataset = dataset.filter(lambda x: x[\"seq\"] is not None)\n",
    "datasets = dataset[\"train\"]\n",
    "\n",
    "\n",
    "\n",
    "# def process_function(examples):\n",
    "#     for i in range(len(examples['seq'])):\n",
    "#         examples['seq'][i] = ' '.join(list(examples['seq'][i]))\n",
    "#     tokenized_examples = tokenizer(examples[\"seq\"], max_length=500, truncation=True)\n",
    "#     tokenized_examples[\"labels\"] = examples[\"label\"]\n",
    "#     return tokenized_examples\n",
    "\n",
    "test_datasets = datasets.map(process_function, batched=True)\n",
    "predictions = trainer.predict(test_datasets)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c819bb80-42ab-4188-8489-cba02ece14e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "452118ae-facd-48ab-8631-d2e927c951eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
